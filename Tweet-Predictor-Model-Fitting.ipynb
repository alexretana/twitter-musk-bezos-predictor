{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23654333",
   "metadata": {},
   "source": [
    "# Tweet Poster Classifier\n",
    "\n",
    "This is a basic Natrual Langaue Processing (NLP) and Supervised Machine Learning (ML) example using real tweets from Elon Musk and Jeff Bezos to demonstrate the capabilities of common classification models and their application to unstructured text data.\n",
    "\n",
    "## Predictor\n",
    "\n",
    "Building the vectorizer will require the following steps:\n",
    "\n",
    " - Clean and Vectorize the corpus, then split into training and testing sets\n",
    " - Decide on a list of Classification Models to train \n",
    " - Create Parameter Grids to uncover the best performing combination\n",
    " - Grid Search using the training set\n",
    " - Evalutate the perfromance of the best models using the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181682c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#silence warnings for this demo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#sklearn tools to preprocess data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#sklearn models to train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#sklearn tools for evaluating models\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff80b08",
   "metadata": {},
   "source": [
    "To begin, the DataFrams from the last Notebook is read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697c629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1422627025068695556</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>244</td>\n",
       "      <td>@Erdayastronaut @ErcXspace We stole the idea f...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 18:34:48 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1422615364479897606</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>191</td>\n",
       "      <td>@flcnhvy Pitch control requires more force tha...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:48:28 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422612139160834050</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>144</td>\n",
       "      <td>@TeslaFruit Thanks Sandy!</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:35:39 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1422608233995382791</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>3527</td>\n",
       "      <td>https://t.co/nNjhPIEhcZ</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:20:08 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1422607954101084161</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>8561</td>\n",
       "      <td>Super Heavy Booster moving to orbital launch m...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:19:01 +0000 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id    handle  retweet_count  \\\n",
       "0  1422627025068695556  elonmusk            244   \n",
       "1  1422615364479897606  elonmusk            191   \n",
       "2  1422612139160834050  elonmusk            144   \n",
       "3  1422608233995382791  elonmusk           3527   \n",
       "4  1422607954101084161  elonmusk           8561   \n",
       "\n",
       "                                                text  \\\n",
       "0  @Erdayastronaut @ErcXspace We stole the idea f...   \n",
       "1  @flcnhvy Pitch control requires more force tha...   \n",
       "2                          @TeslaFruit Thanks Sandy!   \n",
       "3                            https://t.co/nNjhPIEhcZ   \n",
       "4  Super Heavy Booster moving to orbital launch m...   \n",
       "\n",
       "                     mined_at                      created_at  \n",
       "0  2021-08-03 16:36:38.236180  Tue Aug 03 18:34:48 +0000 2021  \n",
       "1  2021-08-03 16:36:38.236180  Tue Aug 03 17:48:28 +0000 2021  \n",
       "2  2021-08-03 16:36:38.236180  Tue Aug 03 17:35:39 +0000 2021  \n",
       "3  2021-08-03 16:36:38.236180  Tue Aug 03 17:20:08 +0000 2021  \n",
       "4  2021-08-03 16:36:38.236180  Tue Aug 03 17:19:01 +0000 2021  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musk_df = pd.read_csv('./data/musk_tweets.csv', index_col=0)\n",
    "musk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7641502a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1233441223232245760</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2554</td>\n",
       "      <td>Discussing climate, sustainability, and preser...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Fri Feb 28 17:17:58 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1224154674804084736</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>13443</td>\n",
       "      <td>I just took a DNA test, turns out I’m 100% @li...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Mon Feb 03 02:16:32 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1222572705066536961</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>2775</td>\n",
       "      <td>Hey, Alexa — show everyone our upcoming Super ...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Wed Jan 29 17:30:21 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220059386694922240</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>5441</td>\n",
       "      <td>#Jamal https://t.co/8ej1rUBXVb</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Wed Jan 22 19:03:20 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219093283265138688</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>9970</td>\n",
       "      <td>Hey, India. We’re rolling out our new fleet of...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Mon Jan 20 03:04:23 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id     handle  retweet_count  \\\n",
       "0  1233441223232245760  JeffBezos           2554   \n",
       "1  1224154674804084736  JeffBezos          13443   \n",
       "2  1222572705066536961  JeffBezos           2775   \n",
       "3  1220059386694922240  JeffBezos           5441   \n",
       "4  1219093283265138688  JeffBezos           9970   \n",
       "\n",
       "                                                text  \\\n",
       "0  Discussing climate, sustainability, and preser...   \n",
       "1  I just took a DNA test, turns out I’m 100% @li...   \n",
       "2  Hey, Alexa — show everyone our upcoming Super ...   \n",
       "3                     #Jamal https://t.co/8ej1rUBXVb   \n",
       "4  Hey, India. We’re rolling out our new fleet of...   \n",
       "\n",
       "                     mined_at                      created_at  \n",
       "0  2021-08-03 16:36:42.400558  Fri Feb 28 17:17:58 +0000 2020  \n",
       "1  2021-08-03 16:36:42.400558  Mon Feb 03 02:16:32 +0000 2020  \n",
       "2  2021-08-03 16:36:42.400558  Wed Jan 29 17:30:21 +0000 2020  \n",
       "3  2021-08-03 16:36:42.400558  Wed Jan 22 19:03:20 +0000 2020  \n",
       "4  2021-08-03 16:36:42.400558  Mon Jan 20 03:04:23 +0000 2020  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bezos_df = pd.read_csv('./data/bezos_tweets.csv',index_col=0)\n",
    "bezos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c9a50",
   "metadata": {},
   "source": [
    "To do a small amount of analysis first, the top 10 most common tokens are printed out. A token in NGram will be groups of words as oppose to single words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b931f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define fucntion to analysis top 10 common tokens\n",
    "def top10Tokens(df, vectorizer):\n",
    "    \"\"\"\n",
    "    provided a dataframe (w/ 'text' column) and a vectorzier, returns top ten results.\n",
    "    \"\"\"\n",
    "    flattened_corpus = \" \".join(df['text'])\n",
    "    text_vector = vectorizer.build_analyzer()(flattened_corpus)\n",
    "    return Counter(text_vector).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb61d046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Elon Musk Phrases: \n",
      "\n",
      "[('erdayastronaut spacex', 15),\n",
      " ('doo doo', 12),\n",
      " ('super heavy', 10),\n",
      " ('self driving', 10),\n",
      " ('fsd beta', 9),\n",
      " ('doo doo doo', 9),\n",
      " ('teslarati klenderjoey', 8),\n",
      " ('ppathole spacex', 8),\n",
      " ('later year', 8),\n",
      " ('teslarati residentsponge', 7)]\n",
      "\n",
      "Top 10 Jeff Bezos Phrases: \n",
      "\n",
      "[('gradatimferociter https', 13),\n",
      " ('blueorigin https', 8),\n",
      " ('blueorigin team', 7),\n",
      " ('launchlandrepeat blueorigin', 7),\n",
      " ('blue origin', 6),\n",
      " ('crew capsule', 6),\n",
      " ('excited announce', 4),\n",
      " ('amazon air', 4),\n",
      " ('huge kudos', 4),\n",
      " ('new shepard', 4)]\n"
     ]
    }
   ],
   "source": [
    "#intialize TfidfVector\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(2,5))\n",
    "\n",
    "#print out results\n",
    "print(\"Top 10 Elon Musk Phrases: \\n\")\n",
    "pprint(top10Tokens(musk_df, vectorizer))\n",
    "\n",
    "print(\"\\nTop 10 Jeff Bezos Phrases: \\n\")\n",
    "pprint(top10Tokens(bezos_df, vectorizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41013a58",
   "metadata": {},
   "source": [
    "It's clear Elon is much more frivilous with what he likes to tweet about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c173f",
   "metadata": {},
   "source": [
    "To prepare the data for Machine Learning Processing, the first step will be to clean the data. This entails using the Natural Langauge ToolKit or NLTK package. A stemmer is used to group words with the same stem. Stemming is essentially converting a conjugated word to its base form. Puncuation and stop words are removed from the corpus as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b1a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion to apply to each tweet. Stems words, and removes puct and stopwords\n",
    "def nltkTextCleaner(text):\n",
    "    \n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    words = nltk.corpus.stopwords.words(\"english\")\n",
    "    \n",
    "    removePunct = re.sub(\"[^a-zA-z]\", \" \", text).split()\n",
    "    clean_stems = [stemmer.stem(i) for i in removePunct if i not in words]\n",
    "    return \" \".join(clean_stems).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3e5b7",
   "metadata": {},
   "source": [
    "As seen before, the number of tweets from both CEO are darastically different. Elon has 1500 tweets, while Jeff only has about 250. This is known as an imbalance in labels, which can lead models to favor predicting the majority class (in this case Elon).\n",
    "\n",
    "To compensate this, the resample fucntion is brought in from the scikit-learn library, which will randomly create duplicates of posts until both classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752507b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resamle bezos tweets until its equal to amount of tweets musk has\n",
    "bezos_df = resample(bezos_df, n_samples = len(musk_df), random_state=42)\n",
    "\n",
    "#concat dataframes\n",
    "combined_df = pd.concat([musk_df, bezos_df])\n",
    "\n",
    "#make variable with the clean text\n",
    "all_text = combined_df['text'].values\n",
    "clean_text = [nltkTextCleaner(i) for i in all_text]\n",
    "\n",
    "#create the labels to be used later\n",
    "labels = combined_df['handle'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc7122c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1422627025068695556</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>244</td>\n",
       "      <td>@Erdayastronaut @ErcXspace We stole the idea f...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 18:34:48 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1422615364479897606</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>191</td>\n",
       "      <td>@flcnhvy Pitch control requires more force tha...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:48:28 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422612139160834050</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>144</td>\n",
       "      <td>@TeslaFruit Thanks Sandy!</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:35:39 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1422608233995382791</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>3527</td>\n",
       "      <td>https://t.co/nNjhPIEhcZ</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:20:08 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1422607954101084161</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>8561</td>\n",
       "      <td>Super Heavy Booster moving to orbital launch m...</td>\n",
       "      <td>2021-08-03 16:36:38.236180</td>\n",
       "      <td>Tue Aug 03 17:19:01 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>911304409803522048</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>561</td>\n",
       "      <td>Future engineer, 9-year-old Ryan, signs Amazon...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Fri Sep 22 19:01:17 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>775324124935778304</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>1340</td>\n",
       "      <td>Blue Origin’s next step…meet New Glenn #NewGle...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Mon Sep 12 13:24:10 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>722248253996019712</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>96</td>\n",
       "      <td>Champagne cracked in the newsroom today. Congr...</td>\n",
       "      <td>2021-08-03 16:36:42.655675</td>\n",
       "      <td>Tue Apr 19 02:19:37 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>688732394442997760</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>292</td>\n",
       "      <td>Believe me, if you’re ever tossed in a foreign...</td>\n",
       "      <td>2021-08-03 16:36:42.655675</td>\n",
       "      <td>Sun Jan 17 14:39:33 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>915046109298520064</td>\n",
       "      <td>JeffBezos</td>\n",
       "      <td>3514</td>\n",
       "      <td>Amazon plane packed with donation of critical ...</td>\n",
       "      <td>2021-08-03 16:36:42.400558</td>\n",
       "      <td>Tue Oct 03 02:49:27 +0000 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3064 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id     handle  retweet_count  \\\n",
       "0    1422627025068695556   elonmusk            244   \n",
       "1    1422615364479897606   elonmusk            191   \n",
       "2    1422612139160834050   elonmusk            144   \n",
       "3    1422608233995382791   elonmusk           3527   \n",
       "4    1422607954101084161   elonmusk           8561   \n",
       "..                   ...        ...            ...   \n",
       "114   911304409803522048  JeffBezos            561   \n",
       "174   775324124935778304  JeffBezos           1340   \n",
       "193   722248253996019712  JeffBezos             96   \n",
       "219   688732394442997760  JeffBezos            292   \n",
       "112   915046109298520064  JeffBezos           3514   \n",
       "\n",
       "                                                  text  \\\n",
       "0    @Erdayastronaut @ErcXspace We stole the idea f...   \n",
       "1    @flcnhvy Pitch control requires more force tha...   \n",
       "2                            @TeslaFruit Thanks Sandy!   \n",
       "3                              https://t.co/nNjhPIEhcZ   \n",
       "4    Super Heavy Booster moving to orbital launch m...   \n",
       "..                                                 ...   \n",
       "114  Future engineer, 9-year-old Ryan, signs Amazon...   \n",
       "174  Blue Origin’s next step…meet New Glenn #NewGle...   \n",
       "193  Champagne cracked in the newsroom today. Congr...   \n",
       "219  Believe me, if you’re ever tossed in a foreign...   \n",
       "112  Amazon plane packed with donation of critical ...   \n",
       "\n",
       "                       mined_at                      created_at  \n",
       "0    2021-08-03 16:36:38.236180  Tue Aug 03 18:34:48 +0000 2021  \n",
       "1    2021-08-03 16:36:38.236180  Tue Aug 03 17:48:28 +0000 2021  \n",
       "2    2021-08-03 16:36:38.236180  Tue Aug 03 17:35:39 +0000 2021  \n",
       "3    2021-08-03 16:36:38.236180  Tue Aug 03 17:20:08 +0000 2021  \n",
       "4    2021-08-03 16:36:38.236180  Tue Aug 03 17:19:01 +0000 2021  \n",
       "..                          ...                             ...  \n",
       "114  2021-08-03 16:36:42.400558  Fri Sep 22 19:01:17 +0000 2017  \n",
       "174  2021-08-03 16:36:42.400558  Mon Sep 12 13:24:10 +0000 2016  \n",
       "193  2021-08-03 16:36:42.655675  Tue Apr 19 02:19:37 +0000 2016  \n",
       "219  2021-08-03 16:36:42.655675  Sun Jan 17 14:39:33 +0000 2016  \n",
       "112  2021-08-03 16:36:42.400558  Tue Oct 03 02:49:27 +0000 2017  \n",
       "\n",
       "[3064 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f159b2",
   "metadata": {},
   "source": [
    "To process the text, it must be transformed into a numeric representation (i.e. a vector). The same vector as before will be used, but with a constraint on how big of a vocabulary to build. Here the vocab limit is set to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924de5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features and lables, assign to common convention of X, y variable names\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (2,4), max_features = 1000)\n",
    "X = vectorizer.fit_transform(clean_text)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0c9e4",
   "metadata": {},
   "source": [
    "A big theme in training prediciton models is that they can be overfitted to the training data. Meaning that it performs better on the training data (almost 'memorizing' anwsers) but generalize worse (scoring lowly on unseen data).\n",
    "\n",
    "To check whether a model is overfitting or not, a fraction of the dataset is put to the side, seperated from the training data, to be used to evaluate how the model performs on unseen data.\n",
    "\n",
    "Scikit Learn provides a simple function to randomly shuffle and seperate data while mantaining the order of the data called train_test_split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into testing and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36fdfb",
   "metadata": {},
   "source": [
    "More than just one algorithm should be tested out because it can usually be ambigiuous which model should perform better. It is better to train various models ands compare them than decide theoretically which one should be best.\n",
    "\n",
    "Even when looking at one algoritm, there are various hyperparameters that can be tuned to reach better performance, but again, instead of speculating, its better to test out all the combinations of parameters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e8617",
   "metadata": {},
   "source": [
    "The models that will be tested out here are the following. Links are provided of the models' scikit learn documentation:\n",
    "\n",
    " - [Logisitic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    " - [MultiLayer Perceptron Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    " - [K Nearest Neighbors Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    " - [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n",
    " - [Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d7c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with initiallized models\n",
    "models = {\n",
    "    \"LR\" : LogisticRegression(penalty = 'l1', solver='liblinear', random_state=42),\n",
    "    \"MLP\" : MLPClassifier(random_state=42),\n",
    "    \"KN\" : KNeighborsClassifier(),\n",
    "    \"SVC\" : SVC(random_state=42),\n",
    "    \"GBC\" : GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "#parameter grids for each model\n",
    "params = {\n",
    "        \"LR\" : {'C' : list(np.power(10.0, np.arange(-3, 3)))},\n",
    "    \n",
    "        \"MLP\" : {\n",
    "            'hidden_layer_sizes' : [50,100,250],\n",
    "            'solver' : ['adam', 'sgd'],\n",
    "            'alpha' : np.power(10.0, np.arange(-4,1))\n",
    "        },\n",
    "    \n",
    "        \"KN\" : {\n",
    "            'n_neighbors': np.arange(2, 6),\n",
    "            'weights' : ['uniform', 'distance']\n",
    "        },\n",
    "    \n",
    "        \"SVC\" : {\n",
    "            'C' : list(np.power(10.0, np.arange(-3, 3))),\n",
    "            'kernel' : ['linear', 'rbf', 'sigmoid']    \n",
    "        },\n",
    "        \"GBC\" : {\n",
    "            'loss' : ['deviance', 'exponential'],\n",
    "            'learning_rate' : list(np.power(10.0, np.arange(-5,0))),\n",
    "            'n_estimators' : [50, 100, 250],\n",
    "            'max_depth' : [3,4,5]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081f564",
   "metadata": {},
   "source": [
    "Since an interative process is being performed, a loop was created to do all the training and collect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ca60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list to append results in\n",
    "best_estimators = []\n",
    "for algorithm, model in models.items():\n",
    "    #create dict that will describe results\n",
    "    best_estimator = {}\n",
    "    \n",
    "    #train using grid search to find best params\n",
    "    trainer = GridSearchCV(model, param_grid = params[algorithm], cv=3)\n",
    "    trainer.fit(X_train, y_train)\n",
    "    \n",
    "    #populate dict with results\n",
    "    best_estimator['algorithm'] = algorithm\n",
    "    best_estimator['estimator'] = trainer.best_estimator_\n",
    "    best_estimator['cv_score'] = trainer.best_score_\n",
    "    best_estimator['params'] = trainer.best_params_\n",
    "    \n",
    "    #create test score using test data\n",
    "    y_pred = trainer.best_estimator_.predict(X_test)\n",
    "    best_estimator['test_score'] = accuracy_score(y_pred, y_test)\n",
    "    \n",
    "    #add results to list\n",
    "    best_estimators.append(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c594e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>estimator</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>params</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10.0, penalty='l1', rando...</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "      <td>0.823913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>MLPClassifier(alpha=1.0, hidden_layer_sizes=10...</td>\n",
       "      <td>0.817169</td>\n",
       "      <td>{'alpha': 1.0, 'hidden_layer_sizes': 100, 'sol...</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KN</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=2)</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC(C=10.0, kernel='sigmoid', random_state=42)</td>\n",
       "      <td>0.815770</td>\n",
       "      <td>{'C': 10.0, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBC</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>0.812973</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.820652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm                                          estimator  cv_score  \\\n",
       "0        LR  LogisticRegression(C=10.0, penalty='l1', rando...  0.814839   \n",
       "1       MLP  MLPClassifier(alpha=1.0, hidden_layer_sizes=10...  0.817169   \n",
       "2        KN                KNeighborsClassifier(n_neighbors=2)  0.814839   \n",
       "3       SVC     SVC(C=10.0, kernel='sigmoid', random_state=42)  0.815770   \n",
       "4       GBC  ([DecisionTreeRegressor(criterion='friedman_ms...  0.812973   \n",
       "\n",
       "                                              params  test_score  \n",
       "0                                        {'C': 10.0}    0.823913  \n",
       "1  {'alpha': 1.0, 'hidden_layer_sizes': 100, 'sol...    0.825000  \n",
       "2           {'n_neighbors': 2, 'weights': 'uniform'}    0.825000  \n",
       "3                   {'C': 10.0, 'kernel': 'sigmoid'}    0.825000  \n",
       "4  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...    0.820652  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out results using pandas\n",
    "pd.DataFrame(data = best_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ea98a",
   "metadata": {},
   "source": [
    "The results show that the best model was tied between the MLP Classifier, the K Nearest Neighbor, and the SVM classifier.\n",
    "\n",
    "All the models got decent results of 82% from the test data. To combare to a base metric, a dummy classifier (aka one that will guess the majority class everytime) would yield 50% (recall that bezos's tweets were resampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
